{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Lending Club\n",
    "Anna Pauxberger\n",
    "\n",
    "Problem Posed: Predict the highest amount of a loan, a customer could get. \n",
    "\n",
    "Lending Club Data from: https://www.lendingclub.com/info/download-data.action\n",
    "\n",
    "1. Data-Preprocessing\n",
    "2. Split Training and Validation Set\n",
    "3. Train Random Forest Classification\n",
    "4. Advise on Loan Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Imbalance** From the shape of the original data sets we can tell that reject and accept data are imbalanced. We could now either decrease the reject set to match the length of the accept data, artificially create new accept data points, or account for that imbalance when we split the training and test data and train the model. I chose to go with the latter. \n",
    "\n",
    "**Variable Choice** We are limited by the variables available in the reject dataset. From those I chose to \n",
    "- omit: \n",
    "    - application date: because it doesn't match the accept dataset, where date listed on the platform is the only one available. \n",
    "    - risk score: Because there is no equivalent score in accept set. Not having a risk score in predicting whether or not a loan will be accepted is a major limitation of this model.\n",
    "    - state: because a geographical variable is represented in the zip code\n",
    "    - policy code: because it predicts the acceptance/ rejection (is correlated with it)\n",
    "- keep: \n",
    "    - loan amount\n",
    "    - debt to income ratio\n",
    "    - zip code: I only account for the zip code, and use it ordinally. Since states are ordered by region, this could make a positive effect. \n",
    "    - employment length: udner one year was set to 0, above 10 years was set to 20 to partially account for the years up to 40 or 50 that a person could have already been employed. This also is a limitation of the model. \n",
    "    - purpose (loan title): By classifying the user input into the 10 largest categories, I create a categorical variable for purpose. One weakness is that the 'other' category is still rather large, which could decrease the significance of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_original = pd.read_csv('RejectStatsA.csv', low_memory=False, skiprows=[0])\n",
    "accept_original = pd.read_csv('LoanStats3a.csv', low_memory=False, skiprows=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((755491, 9), (42538, 145))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reject_original.shape, accept_original.shape # class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject = reject_original[['Amount Requested', 'Debt-To-Income Ratio', 'Zip Code', 'Employment Length', 'Loan Title']]\n",
    "accept = accept_original[['loan_amnt', 'dti', 'zip_code', 'emp_length', 'purpose']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore and drop all nas, because it is only >1% of the data\n",
    "reject = reject.dropna()\n",
    "accept = accept.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edits 1: employment length, zip code, dti\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "reject.columns = ['amount', 'dti', 'zip', 'emp', 'purpose']\n",
    "accept.columns = ['amount', 'dti', 'zip', 'emp', 'purpose']\n",
    "\n",
    "accept['emp'].replace('< 1 year', '0', inplace=True)\n",
    "accept['emp'].replace('10+ years', '20', inplace=True) # between 10 and 40, assuming that's a good representation\n",
    "accept['emp'] = accept['emp'].str.extract('(\\d+)', expand=False)\n",
    "accept['zip'] = accept['zip'].str.extract('(\\d+)', expand=False)\n",
    "accept['zip'] = accept['zip'].str.slice(0,1)\n",
    "\n",
    "reject['dti'].replace('%', '', inplace=True)\n",
    "reject['zip'] = reject['zip'].str.extract('(\\d+)', expand=False)\n",
    "reject['zip'] = reject['zip'].str.slice(0,1)\n",
    "reject['emp'].replace('< 1 year', '0', inplace=True) # could be between 0 and 1, assuming that's the mean or a good repr\n",
    "reject['emp'].replace('10+ years', '20', inplace=True) # between 10 and 40, assuming that's a good representation\n",
    "reject['emp'] = reject['emp'].str.extract('(\\d+)', expand=False)\n",
    "reject['dti'] = reject['dti'].str.split('%', expand=True)[0]\n",
    "\n",
    "\n",
    "reject['accept'] = 0\n",
    "accept['accept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount     float64\n",
       "dti        float64\n",
       "zip        float64\n",
       "emp        float64\n",
       "purpose     object\n",
       "accept     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edits 2: concat, edit type\n",
    "frames = [accept, reject]\n",
    "temp = pd.concat(frames)\n",
    "\n",
    "# convert to floats\n",
    "temp.dti = temp.dti.astype(float)\n",
    "temp.emp = temp.emp.astype(float)\n",
    "temp.accept = temp.accept.astype(float)\n",
    "temp.zip = temp.zip.astype(float)\n",
    "temp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "debt_consolidation    266223\n",
       "other                  96647\n",
       "credit_card            58059\n",
       "home_improvement       44406\n",
       "car                    44181\n",
       "small_business         39575\n",
       "major_purchase         37989\n",
       "medical                19190\n",
       "moving                 18180\n",
       "                       15235\n",
       "Name: purpose, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edits 3: add purpose\n",
    "temp.purpose.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>dti</th>\n",
       "      <th>zip</th>\n",
       "      <th>emp</th>\n",
       "      <th>accept</th>\n",
       "      <th>business</th>\n",
       "      <th>car</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>debt-related</th>\n",
       "      <th>home</th>\n",
       "      <th>medical</th>\n",
       "      <th>other</th>\n",
       "      <th>wedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>27.65</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>8.72</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>17.94</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amount    dti  zip   emp  accept  business  car  credit_card  \\\n",
       "0   5000.0  27.65  8.0  20.0     1.0       0.0  1.0          0.0   \n",
       "1   2500.0   1.00  3.0   0.0     1.0       0.0  1.0          0.0   \n",
       "2   2400.0   8.72  6.0  20.0     1.0       1.0  0.0          0.0   \n",
       "3  10000.0  20.00  9.0  20.0     1.0       0.0  0.0          0.0   \n",
       "4   3000.0  17.94  9.0   1.0     1.0       0.0  0.0          0.0   \n",
       "\n",
       "   debt-related  home  medical  other  wedding  \n",
       "0           0.0   0.0      0.0    0.0      0.0  \n",
       "1           0.0   0.0      0.0    0.0      0.0  \n",
       "2           0.0   0.0      0.0    0.0      0.0  \n",
       "3           0.0   0.0      0.0    1.0      0.0  \n",
       "4           0.0   0.0      0.0    1.0      0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def purpose_transformation(purpose):\n",
    "    purpose = str(purpose).lower()\n",
    "    if 'debt' in purpose: return 'debt-related'\n",
    "    if 'credit card' in purpose: return 'credit_card'\n",
    "    if 'business' in purpose: return 'business'\n",
    "    if 'home' in purpose or 'house' in purpose: return 'home'\n",
    "    if 'car' in purpose: return 'car'\n",
    "    if 'medical' in purpose: return 'medical'\n",
    "    if 'wedding' in purpose: return 'wedding'\n",
    "    return 'other'\n",
    "\n",
    "purpose_temp = temp['purpose'].apply(purpose_transformation)\n",
    "\n",
    "purpose_dummies = pd.get_dummies(purpose_temp, dtype=float)\n",
    "lending = pd.concat([temp, purpose_dummies], axis=1)\n",
    "lending = lending.drop(['purpose'], axis=1)\n",
    "lending.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the training set to contain 70%, and the test set to be 30%. I stratify with regards to the lending_target to balance according to the initial imbalance problem mentioned above. If I had manipulated more variables, I would have also included a validation set which I would have used as test set while training the models, in order to not inform my model by my last resource test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_data = lending.loc[:, lending.columns != 'accept']\n",
    "lending_target = lending.loc[:, lending.columns == 'accept']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    lending_data, lending_target, test_size=0.7, random_state=0, stratify=lending_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((236624, 12), (236624, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((552124, 12), (552124, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model** Out of logistic regression, logistic regression cross validation and the random forest, the latter performed best according to f1_score. The F1 score is the harmonic mean of precision and recall and thus a holistic performance measure of the model. (Coming with limitations. If I care about precision or recall in particular, for example for clinical trial data, it is crucial to look at the outcomes specifically.) \n",
    "\n",
    "** Precision** We can see that we have a 99% precision for predicting 0. Meaning that 99% of all rejects we predict, were actually rejected. For accepted, this is only 25%. Meaning that out of all loans we accept, only 25% would actually get accepted. For practical purposes, this is bad since a lot of people will walk into the offices that we will have to reject. For marketing purposes, this might be good because it makes customers remember our loan giving bank in positive light (as we promise them a loan). \n",
    "\n",
    "\n",
    "**Recall** Recall is 86% for rejected loans, meaning out of all loans that were actually rejected, we detected 86%. This time we have a pretty similar value for acceptance, with 87%. In general, I think this performance is not too bad, as this is just a recommendation service. However, we could do better. \n",
    "\n",
    "**Cross Validation** I apply cross validation using k-fold CV, which splits the training set into 10 sets, iterates through each using 9 parts as training set and 1 part as test (validation) set. My scores have a mean of 86% accuracy, with a rather small standard deviation (0.00). While this sounds good, it's important to not only look at accuracy, since we could technically have good accuracy scores by predicting one class only, if 86% of our data were that class. \n",
    "\n",
    "**Dummy vs Ordinal** I chose to use ordinal type for all variables. Some models (especially logistic regression) perform better when data is put into dummy variables (one hot encoded), since they can then better linearly predict each variable. Random Forest, however, is pretty good at dealing with nominal data. However, since all of my categorical data have rather few categories, I also could have made them dummy variables since it wouldn't have increased the dimensions as much. In a next iteration I would test that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=4, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=4,random_state=0,class_weight='balanced')\n",
    "clf.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.90384274e-02, 3.15204259e-01, 2.69029594e-03, 5.45583833e-01,\n",
       "       2.37808529e-04, 1.11250688e-03, 6.14519745e-03, 1.54616372e-02,\n",
       "       9.24729096e-04, 4.04156661e-04, 4.30815266e-02, 1.15622676e-04])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94142403, 0.05857597],\n",
       "       [0.92042842, 0.07957158],\n",
       "       [0.80007106, 0.19992894],\n",
       "       ...,\n",
       "       [0.34388511, 0.65611489],\n",
       "       [0.72104365, 0.27895635],\n",
       "       [0.79448835, 0.20551165]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3676618014374799"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.84      0.91    224197\n",
      "        1.0       0.23      0.87      0.37     12427\n",
      "\n",
      "avg / total       0.95      0.84      0.88    236624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8427040722693929, 0.0029150214858213483)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(clf, X_train, np.ravel(y_train), cv=10)\n",
    "np.mean(cv), np.std(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advise on Loan Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I create an algorithm that takes a user's input (debt, income, zip code, and employment length in years) and calcualtes the highest loan amount this user can get. I loop through different values, which is rather inefficient. A logistic regression could be more effective here, as I would be able to compute a decisino boundary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user input\n",
    "debt = 1000\n",
    "income = 2000\n",
    "zip_code = 234\n",
    "emp_length = 10     # in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_max = lending.amount.max() + (1/5)*lending.amount.max()\n",
    "loan_amounts = np.arange(loan_max, 0, -500)\n",
    "\n",
    "def loan_optimizer(debt, income, zip_code, emp_length):\n",
    "    loans_secured = [] # 75%, 85%, 95%, 100%\n",
    "    dti = debt/income\n",
    "    for loan in loan_amounts:\n",
    "        user_data = [loan, dti, zip_code, emp_length]\n",
    "        user_data = np.array(user_data).reshape(1, -1)\n",
    "        reject_prob = clf.predict_proba(user_data)[0][0]\n",
    "        accept_prob = clf.predict_proba(user_data)[0][1]\n",
    "        \n",
    "        if accept_prob == 1: \n",
    "            print('A loan of of ', loan, \n",
    "                                   ' $ will get accepted with probability', accept_prob)\n",
    "            return\n",
    "        \n",
    "        if accept_prob > 0.40 and accept_prob < 0.91: \n",
    "            print('A loan of of ', loan, \n",
    "                                   ' $ will get accepted with probability', accept_prob)\n",
    "            return\n",
    "        else: \n",
    "            return('Sorry - No loan can be issued for you.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A loan of of  1680000.0  $ will get accepted with probability 0.41060282947987403\n"
     ]
    }
   ],
   "source": [
    "loan_optimizer(1000, 20000, 234, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Methods used to explore the original data\n",
    "reject_original.head()\n",
    "len(reject_original) \n",
    "list(reject_original)\n",
    "reject_original.dtypes\n",
    "reject_original.isna().sum()\n",
    "\n",
    "accept_original.head()\n",
    "len(accept_original)\n",
    "list(accept_original) \n",
    "accept_original.dtypes\n",
    "accept_original.isna().sum()\n",
    "\n",
    "reject_original['Risk_Score'].value_counts()\n",
    "reject_original.Risk_Score.nunique()\n",
    "accept_original.grade.value_counts()\n",
    "accept_original.zip_code.nunique()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 2: Additional Models with lower F1 Score (thus not used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annapauxberger/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs', class_weight='balanced').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annapauxberger/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [0.88115979, 0.11884021],\n",
       "       [0.41153164, 0.58846836],\n",
       "       ...,\n",
       "       [0.47706258, 0.52293742],\n",
       "       [0.82452578, 0.17547422],\n",
       "       [0.65305918, 0.34694082]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2408141726347531"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "f1_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.80      0.88    224197\n",
      "        1.0       0.15      0.64      0.24     12427\n",
      "\n",
      "avg / total       0.93      0.79      0.84    236624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[178285,  45912],\n",
       "       [  4441,   7986]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annapauxberger/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(cv=5, random_state=0, solver='lbfgs', class_weight='balanced').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annapauxberger/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(552124, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annapauxberger/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [0.87003889, 0.12996111],\n",
       "       [0.45162017, 0.54837983],\n",
       "       ...,\n",
       "       [0.51050384, 0.48949616],\n",
       "       [0.82529935, 0.17470065],\n",
       "       [0.63311277, 0.36688723]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8072715549405568"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.261456966516013"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "f1_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.32986918e-05, -3.38731654e-02,  2.27884667e-02,\n",
       "         1.81527498e-01, -1.16737505e-03,  2.78168308e-02,\n",
       "        -8.84685361e-03,  1.35777279e-01, -2.17549516e-03,\n",
       "        -6.93789243e-03, -1.30904318e-01,  6.27183901e-03]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
